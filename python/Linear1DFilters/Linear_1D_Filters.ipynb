{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear 1D Filter Tutorial\n",
    "\n",
    "- Written by G.M. Boynton for Psych 448 at the University of Washington\n",
    "- Adapted for CSHL Computational Vision course in June 2010\n",
    "- Translated to Python by Michael Waskom in 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy import stats, ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear filters for 1D time-series\n",
    "\n",
    "A 1-D 'filter' is a function that takes in a 1-D vector, like a time-series and returns another vector of the same size. Filtering shows up all over the behavioral sciences, from models of physiology including neuronal responses and hemodynamic responses, to methods for analyzing and viewing time-series data.\n",
    "\n",
    "Typical filters are low-pass and band-pass filters that attenuate specific ranges of the frequency spectrum. In this tutorial we'll focus on the time-domain by developing a simple leaky integrator filter and show that it satisfies the properties of superposition and scaling that make it a linear filter.\n",
    "\n",
    "## The leaky integrator\n",
    "\n",
    "A 'leaky integrator' possibly the simplest filter we can build, but it forms the basis of a wide range of physiologically plausible models of neuronal membrane potentials (such as the Hodgkin-Huxley model), hemodynamic responses (as measured with fMRI), and both neuronal and behavioral models of adaptation, such as light and contrast adaptation.\n",
    "\n",
    "A physical example of a 'leaky integrator' is a bucket of water with a hole in the bottom. The rate that the water flows out is proportional to the depth of water in the bucket (because the pressure at the hole is proportional to the volume of water). If we let `y(t)` be the volume of water at any time `t`, then our bucket can be described by a simple differential equation:\n",
    "\n",
    "$$\\frac{dy}{dt} = -\\frac{y}{k}$$\n",
    "\n",
    "Where $k$ is the constant of proportionality. A large $k$ corresponds to a small hole where the water flows out slowly. You might know the closed-form solution to this differential equation, but hold on - we'll get to that later.\n",
    "\n",
    "We need to add water to the bucket. Let $s(t)$ be the time-course of the flow of water into the bucket, so $s(t)$ adds directly to the rate of change of $y$:\n",
    "\n",
    "$$\\frac{dy}{dt} = s - \\frac{y}{k}$$\n",
    "\n",
    "A physiological example of a leaky integrator is if $y$ is the membrane potential of a neuron where the voltage leaks out at a rate in proportion to the voltage difference (potential) and $s$ is the current flowing into the cell. This is the basis of a whole class of models for mebrane potentials, including the famous Hodgkin-Huxley model.\n",
    "\n",
    "We can easily simulate this leaky integrator in discrete steps of time by updating the value of $y$ on each step according to the equation above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_integrator(t, s, k):\n",
    "    \"\"\"Simulate the leaky integration filter.\"\"\"\n",
    "    dx = t[1] - t[0]\n",
    "    y = np.zeros(t.shape)\n",
    "    for i, t_i in enumerate(t[:-1]):\n",
    "        dy = s[i] - y[i] / k\n",
    "        y[i + 1] = y[i] + dy * dt\n",
    "    return y\n",
    "\n",
    "def boxcar(t, dur, start=0, amp=None):\n",
    "    \"\"\"Define a boxcar stimulus\"\"\"\n",
    "    amp = 1 / dur if amp is None else amp\n",
    "    s = np.zeros(t.shape)\n",
    "    s[(t >= start) & (t < (start + dur))] = amp\n",
    "    return s\n",
    "\n",
    "def plot_resp(t, s, y, f=None):\n",
    "    \"\"\"Plot the input and output of a filter.\"\"\"\n",
    "    if f is None:\n",
    "        f, (ax_i, ax_o) = plt.subplots(2, sharex=True)\n",
    "    else:\n",
    "        ax_i, ax_o = f.axes\n",
    "    ax_i.plot(t, s, lw=2, color=\"C0\")\n",
    "    ax_o.plot(t, y, lw=2, color=\"C1\")\n",
    "    ax_i.set(ylabel=\"Input\")\n",
    "    ax_o.set(xlabel=\"Time (s)\", ylabel=\"Output\")\n",
    "    f.tight_layout()\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens to an input that is $1$ for 1 second and then $0$ thereafter.\n",
    "\n",
    "For our first example, we'll let $k = \\infty$, so there's no hole in the bucket (or the hole is infinitely small)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = .001\n",
    "maxt = 5\n",
    "t = np.arange(0, maxt, dt)\n",
    "s = boxcar(t, 1)\n",
    "y = leaky_integrator(t, s, k=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_resp(t, s, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll add the hole in the bucket by setting $k = 1$, See how the bucket fills up during the first second while $s(t) = 1$.  The level of water in the bucket is the integral of $s(t)$ over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = leaky_integrator(t, s, k=1)\n",
    "plot_resp(t, s, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try this again with a bigger hole by letting $k = \\frac{1}{5}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = leaky_integrator(t, s, k=.2)\n",
    "plot_resp(t, s, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time the water nearly reached an asymptotic level. This is because the flow rate out the bottom eventually reached the rate of flow into the bucket. With $k=\\frac{1}{5}$, can you figure out why the asymptotic level is 0.2? Notice also how the water drains out more quickly. \n",
    "The size of the hole, $k$, is called the 'time-constant' of this leaky integrator.\n",
    "\n",
    "The following interactive widget will let you play with the time constant of the integrator and see how it interacts with the duration of the stimulus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def leak_tutorial(k=(0, 2, .1), dur=(0, 2, .1)):\n",
    "    s = boxcar(t, dur, amp=1)\n",
    "    y = leaky_integrator(t, s, k)\n",
    "    f = plot_resp(t, s, y)\n",
    "    plt.setp(f.axes, ylim=(0, 1.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses to short impulses\n",
    "\n",
    "Our previous example had water flowing into the bucket at 1 gallon/second for one second. What happens when we splash in that gallon of water in a much shorter period of time, say within 1/10th of a second?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = .2\n",
    "dur = .01\n",
    "s = boxcar(t, dur)\n",
    "y = leaky_integrator(t, s, k)\n",
    "plot_resp(t, s, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what happens when the same amount of water splashed in 1/100th of a second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dur = .001\n",
    "s = boxcar(t, dur)\n",
    "y = leaky_integrator(t, s, k)\n",
    "plot_resp(t, s, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare these two responses - they're nearly identical. This is because for short durations compared to the time-constant, the leaky integrator doesn't leak significantly during the input, so the inputs are effectively the same.\n",
    "\n",
    "How long in duration can you let the stimulus get before it starts significantly affecting the shape of the response? How does this depend on the time-constant of the leaky integrator?\n",
    "\n",
    "This behavior is an explanation for \"Bloch's Law\", the phenomenon that brief flashes of light are equally detectable as long as they are very brief, and contain the same amount of light. Indeed, the temporal properties of the early stages of the visual system are typically modeled as a leaky integrator.\n",
    "\n",
    "This response to a brief '1-gallon' (or 1 unit) stimulus is called the 'impulse response' and has a special meaning which we'll get to soon.\n",
    "\n",
    "## Scaling\n",
    "\n",
    "It should be clear by the way the stimulus feeds into the response that doubling the input doubles the peak of the response. Since the recovery falls of in proprtional to the current value, you can convince yourself that the whole response scales with the size of the input. Here's an example of the response to two brief pulses of different sizes separated in time. You'll see that the shape of the two responses are identical - they only vary by a scale-factor. This is naturally called 'scaling'. Mathematically, if $L(s(t))$ is the response of the system to a stimulus $s(t)$, then $L(ks(t)) = kL(s(t))$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dur = .01\n",
    "s = boxcar(t, dur, start=0, amp=3) + boxcar(t, dur, start=3, amp=1)\n",
    "y = leaky_integrator(t, s, k)\n",
    "plot_resp(t, s, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Superposition\n",
    "\n",
    "In the last example, the second stimulus (splash of water) occurred long after the response to the first stimulus was over. What happens when the second stimulus happens sooner, while the response to the first splash is still going on?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = .2\n",
    "dt = .001\n",
    "maxt = 2\n",
    "t = np.arange(0, maxt, dt)\n",
    "\n",
    "dur = .01\n",
    "\n",
    "s1 = boxcar(t, dur, start=0)\n",
    "y1 = leaky_integrator(t, s1, k)\n",
    "\n",
    "s2 = boxcar(t, dur, start=.1)\n",
    "y2 = leaky_integrator(t, s2, k)\n",
    "\n",
    "y12 = leaky_integrator(t, s1 + s2, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we plot the responses to each stimulus, then the sum of the filtered outputs ($y_1 + y_2$) *and* the filtered sum of the inputs ($y_{1+2}$), we can see that the latter two responses lie on top of each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plot_resp(t, s1, y1)\n",
    "plot_resp(t, s2, y2, f=f);\n",
    "\n",
    "_, ax = f.axes\n",
    "ax.plot(t, y1 + y2, lw=2, color=\"C2\")\n",
    "ax.plot(t, y12, lw=2, color=\".1\", dashes=(3, 3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words,\n",
    "\n",
    "$$L(s_1 + s_2) = L(s_1) + L(s_2).$$\n",
    "\n",
    "This property is called **superposition**.  By the way, we're also assuming\n",
    "that the time-constant is fixed so that the shape of the response to a\n",
    "stimulus doesn't vary with when it occurs.  This property is called\n",
    "**shift invariance**.\n",
    "\n",
    "A system that has both the properties of scaling and superposition is\n",
    "called a **linear system**, and one with shift invariance is called (wait\n",
    "for it) a **shift-invariant linear system**.\n",
    "\n",
    "Use the following interactive widget to see how the filter sums impulses that happen at different delays from each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def shift_tutorial(k=(0, 2, .1), delay=(0, 2, .1)):\n",
    "    s = boxcar(t, dt, amp=1) + boxcar(t, dt, delay, amp=1)\n",
    "    y = leaky_integrator(t, s, k)\n",
    "    f = plot_resp(t, s, y)\n",
    "    f.axes[0].set(ylim=(0, 2.1))\n",
    "    f.axes[1].set(ylim=(0, dt * 2.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Analytical solution for the leaky integrator\n",
    "\n",
    "The differental equation that describes the leaky integrator is very easy to solve analyitically. If\n",
    "\n",
    "$$\\frac{dy}{dt} = -\\frac{y}{k},$$\n",
    "\n",
    "then\n",
    "\n",
    "$$\\frac{dy}{y} = -\\frac{dt}{k}.$$\n",
    "\n",
    "Integrating both sides over time yields\n",
    "\n",
    "$$\\log(y) = -\\frac{t}{k}+C.$$\n",
    "\n",
    "Exponentiating:\n",
    "\n",
    "$$y = e^{-t/k+C}.$$\n",
    "\n",
    "If we let y(0) = 1, then C=0 so\n",
    "\n",
    "$$y = e^{-t/k}.$$\n",
    "\n",
    "Let's compare the simulated to the analytical impulse response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt, maxt = .01, 1\n",
    "t = np.arange(0, maxt, dt)\n",
    "\n",
    "s = boxcar(t, dt)\n",
    "h = leaky_integrator(t, s, k)\n",
    "hh = np.exp(-t / k)\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.plot(t, h, label=\"Simulated\")\n",
    "ax.plot(t, hh, dashes=(3, 2), label=\"Analytical\")\n",
    "ax.set(xlabel=\"Time (s)\", ylabel=\"Response\")\n",
    "ax.legend()\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's pretty close. It'd be even closer if we used a smaller discrete time\n",
    "step for our simulation.  It'd be *even* closer if we used a less bozo\n",
    "simulation technique, like a [Runge-Kutta method](https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods) or other more\n",
    "sophisticated method of numerical approximating a differential equation.\n",
    "\n",
    "---\n",
    "\n",
    "## Convolution\n",
    "\n",
    "The properties of scaling and superposition have a significant consequence - if we think of any complicated input as a sequence of scaled impulses, then the output of the system to this input can be predicted by a sum of shifted and scaled impulse response functions. Here's an example where the input has three impulses at time-points 1, 6 and 11:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1, t2, t3 = tps = np.array([1, 6, 11]) - 1\n",
    "s = np.zeros(t.shape)\n",
    "s[[t1, t2, t3]] = 1 / dt\n",
    "y = leaky_integrator(t, s, k)\n",
    "f = plot_resp(t, s, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response at time point, say 16, is predicted by the sum of the response to the three inputs. Each of these three inputs produces the same shaped impulse-response, so the response at time 16 is the sum of the impulse response function evaluated at three points in time.\n",
    "\n",
    "Plot the response to the three impulses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = f. axes\n",
    "for i in range(t.size):\n",
    "    ax.plot(t[i:-1], s[i] * h[:-(i+1)] * dt, c=\"C2\")\n",
    "display(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response to the three inputs at time point 16 is the impulse response function evaluated at the time since the input occured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 16\n",
    "for tp_i in tps:\n",
    "    ax.plot(t[idx], h[idx - tp_i], c=\"C2\", marker=\"o\")\n",
    "display(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Superposition means that the response to the system is the sum of these three values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = h[idx - tps].sum()\n",
    "ax.plot(t[idx], r, c=\"C1\", marker=\"o\")\n",
    "display(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any stimulus, the response at time-point 16 will be the sum of shifted, scaled versions of the impulse response function. This loop should give us the same number as the calculation above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = sum(s[i] * h[idx - i] * dt for i in range(t.size))\n",
    "ax.plot(t[idx], rr, c=\".1\", marker=\"x\")\n",
    "display(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response at all time-points can be calculated as above by looping through time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = np.zeros(t.shape)\n",
    "for j in range(t.size):\n",
    "    rr[j] = sum(s[i] * h[j - i] * dt for i in range(t.size))\n",
    "ax.plot(t, rr, c=\".1\", dashes=(3, 3))\n",
    "display(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This operation is called 'convolution', and can be implemented by the function `numpy.convolve`. This function takes in two vectors of length `m` and `n` and returns a vector of length `m + n - 1`. If the first vector is the stimulus and the second is the impulse response, then you'd think that the output would have length `m`. It's longer because the function pads the inputs with zeros so that we get the entire response to the very last input. We'll truncate the output to the length of the input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rconv = np.convolve(s, h) * dt\n",
    "ax.plot(t, rconv[:t.size], c=\"C1\", marker=\"x\")\n",
    "display(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response to arbitrary stimulus\n",
    "\n",
    "With convolution and the analytical solution to the leaky integrator, we can predict the response to of the system to any input, like a random series of scaled impulses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt, maxt = .01, 4\n",
    "t = np.arange(0, maxt, dt)\n",
    "k = .2\n",
    "h = np.exp(-t / k)\n",
    "\n",
    "rng = np.random.RandomState(seed=100)\n",
    "s = np.floor(rng.rand(t.size) + .05) * np.round(rng.rand(t.size) * 5) / dt\n",
    "y = np.convolve(s, h)[:t.size] * dt\n",
    "plot_resp(t, s, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cascades of leaky integrators\n",
    "\n",
    "It is common to model sensory systems with a 'cascade' of leaky integrators, where the output of one integrator feeds into the input of the next one. You can think of this as a series of buckets hanging below eachother, where the flow of water out the bottom bucket is the output of the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt, maxt = .001, 4\n",
    "t = np.arange(0, maxt, dt)\n",
    "\n",
    "s = boxcar(t, dt)\n",
    "y = s.copy()\n",
    "k = .1\n",
    "n = 4\n",
    "\n",
    "for _ in range(n):\n",
    "    y = leaky_integrator(t, y, k) / k\n",
    "f = plot_resp(t, s, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This response of a cascade of leaky integrators to an impulse turns out to be the PDF of the Gamma distribution with shape $n$ and scale $k$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = stats.gamma(n, scale=k).pdf(t)\n",
    "_, ax = f.axes\n",
    "ax.plot(t, h, dashes=(3, 3), color=\".1\")\n",
    "display(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This interactive widget lets you play with the parameters of the cascade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def cascade_tutorial(n=(2, 5), k=(.1, 1, .05)):\n",
    "    s = boxcar(t, dt, amp=1)\n",
    "    h = stats.gamma(n, scale=k).pdf(t)\n",
    "    f = plot_resp(t, s, h)\n",
    "    f.axes[1].set(ylim=(0, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses of a linear system to an arbitrary stimulus\n",
    "\n",
    "Here's the response of the cascade of leaky integrators to a white noise stimulus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = rng.randn(t.size)\n",
    "y = np.convolve(s, h)[:t.size]\n",
    "plot_resp(t, s, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how smooth the output is? If you think about how convolution acts, the response at each time point is the sum of the previous inputs weighted by the impulse-response function going back in time. The impulse response function of the cascade of leaky integrators (the Gamma function) is a smooth bump, so the response at any given time is a weighted average of the previous inputs. This effectively smooths out the bumps in the input. If you know something about the frequency domain, what do you think this does to the input in terms of frequencies?\n",
    "\n",
    "---\n",
    "\n",
    "## Response to sinusoids\n",
    "\n",
    "Following up on this smoothing observation, we'll look at output of our cascade of leaky integrators to sinusoids of different frequencies.\n",
    "\n",
    "Note that we're going to use a different convolution function here. The `convolve` function in numpy doesn't do the circular convolution that we want, so we need to reach for a convolution function from the `scipy` image-processing library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt, maxt = .01, 10\n",
    "t = np.arange(0, maxt, dt)\n",
    "h = stats.gamma(4, scale=.2).pdf(t)\n",
    "\n",
    "freq = .4  # Hz\n",
    "s = np.sin(2 * np.pi * freq * t)\n",
    "y = ndimage.convolve(s, h, mode=\"wrap\") * dt\n",
    "plot_resp(t, s, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try again with a higher frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = 2  # Hz\n",
    "s = np.sin(2 * np.pi * freq * t)\n",
    "y = ndimage.convolve(s, h, mode=\"wrap\") * dt\n",
    "plot_resp(t, s, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This illustrates a unique property of shift-invariant linear systems: The response to any sinusoid is a sinusoid of the same frequency, scaled in amplitude and delayed in phase (The wobbly part in the beginning is because at the beginning, the input into the filter isn't a complete sinusoid until time has reached the duration of the impulse response).\n",
    "\n",
    "This only works for sinusoids - other functions (like square waves or whatever) will change shape after being passed through the filter.\n",
    "\n",
    "Let's calculate the amplitude of the output sinusoid for different frequencies to see how the filter attenuates higher and higher frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cycles = np.arange(1, 21)\n",
    "amp = np.zeros(n_cycles.size)\n",
    "for i, n in enumerate(n_cycles):\n",
    "    s = np.sin(2 * np.pi * n * t / maxt)\n",
    "    y = ndimage.convolve(s, h, mode=\"wrap\") * dt\n",
    "    amp[i] = (y.max() - y.min()) / 2\n",
    "\n",
    "f, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.plot(n_cycles, amp, marker=\"o\")\n",
    "ax.set(xlabel=\"Frequence of input (cycles)\",\n",
    "       ylabel=\"Amplitude of output\")\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way a linear filter attenuates a sinusoid matches the amplitudes of the fft of the filter's impulse response function. What's the significance of this?\n",
    "\n",
    "We know that:\n",
    "\n",
    "1. Any time-series can be represented as a sum of scaled sinsoids\n",
    "2. A linear system only scales and shifts sinusoids\n",
    "3. The response to the sum of inputs is equal to the sum of the responses\n",
    "4. The fft of the impulse response determines how the filter scales the sinusoids\n",
    "\n",
    "Together, this means that there are two ways to calculate the response to a linear system: (1) convolving with the impulse response function and (2) multiplying the fft of the input with the fft of the impulse response function. Convolution in the time domain equals point-wise multiplication in the frequency domain.\n",
    "\n",
    "This will make more sense with an example. We'll make a band-pass filter by taking the FFT of an impulse, attenuating the amplitudes within a frequency band with a Gaussian, and taking the inverse FFT to get the filter in the time domain. First, we'll define some functions to help us with this task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If these functions come up elsewhere we'll probably want\n",
    "# to define them in a helper library\n",
    "def complex_to_real(F, t):\n",
    "    \"\"\"Return real-valued amplitudes and phases from fft convention.\"\"\"\n",
    "    nt = t.size\n",
    "    dt = t[1] - t[0]\n",
    "\n",
    "    dc = F[0] / nt\n",
    "    amp = 2 * np.abs(F) / nt\n",
    "    ph = -180 * np.angle(F) / np.pi\n",
    "\n",
    "    nf = np.ceil(nt / 2) + 1\n",
    "    idx = slice(1, int(nf))\n",
    "    freq = np.abs(np.fft.fftfreq(t.size, dt))\n",
    "    \n",
    "    Y = dict(\n",
    "        dc=dc,\n",
    "        ph=ph[idx],\n",
    "        amp=amp[idx],\n",
    "        freq=freq[idx],\n",
    "    )\n",
    "    return Y\n",
    "\n",
    "\n",
    "def real_to_complex(Y, t):\n",
    "    \"\"\"Return complex-valued vector in fft convention.\"\"\"\n",
    "    nt = t.size\n",
    "    dt = t[1] - t[0]\n",
    "    F = np.zeros(nt, np.complex)\n",
    "\n",
    "    nf = Y[\"freq\"].size\n",
    "    amp = nt * Y[\"amp\"] / 2\n",
    "    ph = -np.pi * Y[\"ph\"] / 180\n",
    "    z = amp * np.exp(-ph * 1j)\n",
    "    \n",
    "    F[0] = Y[\"dc\"] * nt\n",
    "    F[1:nf + 1] = z\n",
    "    F[nf:] = z.conj()[::-1]\n",
    "\n",
    "    return F\n",
    "\n",
    "\n",
    "def plot_fft(t, y):\n",
    "    \"\"\"Plot input and positive frequency spectrum.\"\"\"\n",
    "    Y = complex_to_real(np.fft.fft(y), t)\n",
    "    f, (ax_t, ax_f) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    ax_t.plot(t, y)\n",
    "    ax_f.stem(Y[\"freq\"], Y[\"amp\"], basefmt=\" \", markerfmt=\".\")\n",
    "    ax_t.set(xlabel=\"Time (s)\", ylabel=\"Amplitude\", xlim=(t.min(), t.max() + dt))\n",
    "    ax_f.set(xlabel=\"Frequency (Hz)\", ylabel=\"Amplitude\", ylim=(0, None))\n",
    "    f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt, maxt = .01, 1\n",
    "t = np.arange(0, maxt, dt)\n",
    "\n",
    "# Delta function at time point 50\n",
    "y = (t == t[50]).astype(float)\n",
    "F = np.fft.fft(y)\n",
    "Y = complex_to_real(F, t)\n",
    "\n",
    "# Attenuate the amplitudes with a Gaussian\n",
    "g_center, g_width = 6, 2  # Hz\n",
    "Y[\"amp\"] *= np.exp(-(Y[\"freq\"] - g_center) ** 2 / g_width ** 2)\n",
    "\n",
    "# Take the inverse Fourier transform\n",
    "y_recon = np.fft.ifft(real_to_complex(Y, t)).real\n",
    "\n",
    "plot_fft(t, y_recon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The impulse response function of this band-pass filter is a Gabor. We can\n",
    "describe this filter entirely by either this impulse response function or\n",
    "by it's fft (including the phase, which isn't plotted here).  Think about\n",
    "what happens when you convolve a time-series with this Gabor.  At each\n",
    "time step we center the Gabor on the time series and do a point-wise\n",
    "mulitplication and add up the numbers.  If the time-series is a sinusoid\n",
    "that modulates at the frequency of the Gabor, you can see how this leads\n",
    "to a large response. This is an ideal input - anything else will lead to\n",
    "a weaker outut. Hence the band-pass property of the filter.\n",
    "\n",
    "This filter is a little strange in the time-domain because it spreads\n",
    "both forward and backward in time.  In a sense, it responds to parts of\n",
    "the input that haven't happened yet. A more realistic impulse response\n",
    "function for the time domain only reponds to the past.  This is called a\n",
    "'causal filter'. The leaky integrator is an example of a causal filter.\n",
    "\n",
    "How do we build a causal band-pass filter?  One way is to build it in the\n",
    "time domain as a difference of two low-pass filters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1 / 40\n",
    "h1 = stats.gamma(4, scale=k).pdf(t)\n",
    "h2 = stats.gamma(5, scale=k).pdf(t)\n",
    "h = h1 - h2\n",
    "plot_fft(t, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the plot of fourier spectrum, this filter has a maximum\n",
    "sesnsitivity to frequencies around 3 Hz. You can also see this from the\n",
    "shape of the impulse response. It wiggles up and down one cycle in about\n",
    "1/3 of a second, which is 3Hz. A convolution with a 3Hz sinusoid will\n",
    "produce the largest response.\n",
    "\n",
    "---\n",
    "\n",
    "## An example: the hemodynamic response function\n",
    "\n",
    "Note: this last section overlaps with beginning of the ER_fMRI tutorial.\n",
    "\n",
    "Functional MRI (fMRI) measures changes in blood flow and oxygenation associated with the underlying neuronal response. The most common method for analyizing fMRI data uses the 'general linear model' that assumes that the 'hemodynamic coupling' process acts as a linear shift-invariant filter. Back in 1996 Boynton and Heeger tested this idea and found that the impulse response function acts like a cascade of leaky integrators with these typical parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1  # seconds\n",
    "delay = 2  # seconds\n",
    "n_cascades = 3\n",
    "\n",
    "dt, maxt = .01, 15\n",
    "t = np.arange(0, maxt, dt)\n",
    "hdr = stats.gamma(n_cascades, loc=2, scale=k).pdf(t)\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.plot(t, hdr)\n",
    "ax.set(xlabel=\"Time (s)\", ylabel=\"Amplitude\")\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One kind of fMRI experimental design is a 'blocked design' where two conditions alternate back and forth. A Typical period for a blocked design is something like 25 seconds. If we assume that the neuronal response is following the stimulus closely in time (compared to the hemodyanmic response), the neuronal response might look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt, maxt = .01, 120\n",
    "t = np.arange(0, maxt, dt)\n",
    "period = 25\n",
    "s = np.sign(np.sin(2 * np.pi * t / period))\n",
    "y = np.convolve(s, hdr)[:t.size] * dt\n",
    "plot_resp(t, s, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is the expected shape of the fMRI response. Many software packages will use a convolution with the stimulus design to produce an expected response like this as a template to compare to the actual fMRI data. This template is correlated with each voxel's time-series to produce a number between zero and 1, where 1 is a perfect fit. This produces a 'parameter map' that can tell us which brain areas are responding as expected to the experimental paradigm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
