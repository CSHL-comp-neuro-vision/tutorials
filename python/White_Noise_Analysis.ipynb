{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# White noise tutorial\n",
    "\n",
    "This is a notebook which simulates a white noise experiment.\n",
    "\n",
    "In brief, we're going to simulate the neural response to a one dimensional visual stimulus (luminance with respect to the mean, or contrast) and then reconstruct the mechanism of the neural response using the techniques described in the handout by E.J. Chichilnisky.  \n",
    "\n",
    "The neural response is simulated as a non-homogenous Poisson process whose rate parameter (which will be called `nonlin_resp` below) is a linear function of the stimulus (which will be called `lin_resp` below) put through a static, single-valued non-linearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats, optimize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to run the experiment for 600 seconds, or 10 minutes.  The method works better with longer times, but this works well enough for the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 600 * 1000  # Time is measured in msecs\n",
    "stim_samp_time = 10  # 100 Hz monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our \"monitor\" (device which generates the stimulus) refreshes the display at 100 HZ, or once every 10 msecs.\n",
    "\n",
    "At each frame, the intensity of the uniform screen changes: it is drawn randomly from a particular probability distribution. The exact nature of the probability distribution is not terribly important. However, it is important that 1) the distribution be symmetric about zero and that 2) the contrast on each frame is uncorrelated with the others (this is the definition of a \"white\" random process).\n",
    "\n",
    "As an aside: For stimuli that vary in space and time, the distribution must be symmetric about the origin. For practical purposes, this means it should be Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = sum(map(ord, \"white noise\"))\n",
    "rng = np.random.default_rng(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = duration // stim_samp_time\n",
    "x = np.clip(rng.normal(0, 1 / 3, n_samples), -1, 1)\n",
    "stimulus = np.repeat(x, stim_samp_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 3))\n",
    "ax.plot(stimulus[:1000])\n",
    "ax.set(\n",
    "    xlabel=\"Time (ms)\",\n",
    "    ylabel=\"Stimulus contrast\",\n",
    "    title=\"First 1 second of stimulus\",\n",
    "    xlim=(0, 1000),\n",
    "    ylim=(-1, 1),\n",
    ")\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Linear response\n",
    "\n",
    "Now compute the linear response using a 3 stage cascade of exponential lowpass filters. You could substitute other linear filters here if you wanted to, but this one is pretty simple. The 3rd row of y is the linear response. This takes a couple of minutes to calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_resp = np.zeros((duration, 3))\n",
    "tau = 15\n",
    "for i, s_i in enumerate(stimulus[:-1]):\n",
    "    lin_resp[i + 1, 0] = lin_resp[i, 0] + (1 / tau) * (s_i - lin_resp[i, 0])\n",
    "    lin_resp[i + 1, 1] = lin_resp[i, 1] + (1 / tau) * (lin_resp[i, 0] - lin_resp[i, 1])\n",
    "    lin_resp[i + 1, 2] = lin_resp[i, 2] + (1 / tau) * (lin_resp[i, 1] - lin_resp[i, 2])\n",
    "\n",
    "# Getting rid of the first- and second-order filtered signals, we only want the third one.\n",
    "lin_resp = lin_resp[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear response is just a lowpass filtered version of the stimulus. The top panel of the figure shows the first second of the stimulus, the small middle panel shows the impulse response of the linear filter, and the third panel shows the first second of the linear response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax_stim, ax_resp) = plt.subplots(2, figsize=(8, 7), sharex=True)\n",
    "\n",
    "ax_stim.plot(stimulus[:1000])\n",
    "ax_resp.plot(lin_resp[:1000])\n",
    "\n",
    "ax_stim.set(\n",
    "    title=\"Stimulus\",\n",
    "    xlim=(0, 1000),\n",
    "    ylim=(-1, 1),\n",
    "    \n",
    ")\n",
    "\n",
    "ax_resp.set(\n",
    "    title=\"Linear response\",\n",
    "    xlabel=\"Time (ms)\",\n",
    "    ylim=(-.35, .35),\n",
    ")\n",
    "\n",
    "f.tight_layout(h_pad=10)\n",
    "\n",
    "times = np.arange(200)\n",
    "impulse_resp = times ** 2 * np.exp(-times / tau)\n",
    "\n",
    "ax_kern = f.add_axes([.1, .41, .2, .2])\n",
    "ax_kern.plot(times, impulse_resp, color=\"r\")\n",
    "ax_kern.text(100, 50, \"Imp. Resp.\")\n",
    "ax_kern.set(xticks=[], yticks=[]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Non-linear response\n",
    "\n",
    "Under the simple non-linear (SNL) model, the firing rate of a neuron is a single-valued non-linear function of an underlying linear response. We can pick any such function we want, and, for this example, we've decided on the cumulative Gaussian function (the integral of a Gaussian probability density function). The way we've parameterized it, this function has three arguments: the slope (alpha), the point of inflection (-beta/alpha), and the upper asymptote (gamma). This function relates the probability of firing to the linear response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 25\n",
    "beta = -2\n",
    "gamma = .15\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "r = np.linspace(-.25, .3)\n",
    "ax.plot(r, gamma * stats.norm.cdf(alpha * r + beta), lw=5)\n",
    "ax.set(\n",
    "    xlim=(-.25, .3),\n",
    "    ylim=(0, gamma),\n",
    "    xlabel=\"Linear response\",\n",
    "    ylabel=\"P(firing)\",\n",
    ")\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we're applying this non-linear transformation on the linear response of our simulated neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlin_resp = gamma * stats.norm.cdf(alpha * lin_resp + beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this non-linear response to simulate a Poisson-ish spike train..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr = rng.binomial(1, nonlin_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and we can count up the number of spikes fired by the neuron in each 10 msec wide bin (each screen refresh)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_counts = np.sum(np.split(xr, duration // stim_samp_time), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we constructed a white noise stimulus, we linearly filtered it, put this linearly filtered signal through a non-linear function to calculate an underlying firing rate of the cell, and used this underlying firing rate to simulate spikes coming out of the cell. Here's the first second of each of these functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(4, figsize=(8, 8), sharex=True)\n",
    "\n",
    "axes[0].plot(lin_resp[:1000])\n",
    "axes[1].plot(nonlin_resp[:1000])\n",
    "axes[2].plot(xr[:1000])\n",
    "axes[3].plot(np.arange(0, duration, stim_samp_time)[:100], spike_counts[:100])\n",
    "\n",
    "axes[0].set(title=\"Linear response\", ylim=(-.35, .35))\n",
    "axes[1].set(title=\"Firing probability\", ylim=(0, .2))\n",
    "axes[2].set(title=\"# of spikes (1 ms bins)\", ylim=(0, 2))\n",
    "axes[3].set(title=\"# of spikes (10 ms bins)\", ylim=(0, 5),\n",
    "            xlabel=\"Time (ms)\", xlim=(0, 1000))\n",
    "\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Spike-triggered average\n",
    "\n",
    "Now we compute the spike-triggered average stimulus. This is accomplished by taking the 300 milliseconds of stimulus immediately preceding each spike and adding them together. This sum is then divided by the total number of spikes fired over the course of the entire experiment to determine the average stimulus preceding a spike. This spike-triggered average is, in a sense, a template for what the neuron is \"looking for\" in the stimulus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 300\n",
    "a = np.zeros(window_size)\n",
    "spike_times, = np.nonzero(xr)\n",
    "for t in spike_times[spike_times > window_size]:\n",
    "    a += stimulus[t - window_size:t]\n",
    "a /= xr.sum()\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.plot(np.arange(-window_size, 0), a)\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A powerful result from the theory of white noise analysis states that if the neuron satisfies the assumptions of the SNL model, and the stimulus is drawn according to a distribution which is symmetric about the origin, the spike-triggered average converges, as the time of the experiment goes to infinity, to to the (time-reversed) impulse response of the linear part of the SNL system (up to an arbitrary scale factor). To the extent that neurons are well- modeled as SNL systems, this means that we can easily measure the linear component. Because this is a tutorial, we know exactly what filtering was done on the stimulus to get the linear response (\"linearResp\"). Recall that it was a cascade of three first-order exponential filters. Below, we compare the spike-triggered average to the impulse response of the filter we used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.arange(window_size)\n",
    "impulse_resp = times ** 2 * np.exp(-times / tau)\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.plot(impulse_resp / impulse_resp.max())\n",
    "ax.plot(a[::-1])\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a discrepancy between the impulse response of the filter and the (time-flipped) spike-triggered average. One is a scaled version of the other. There is an ambiguity between the magnitude of the linear response and the scale of the non-linear function (intuitively, we could get identical neural responses either by scaling the linear response or by scaling the subsequent non-linear function).\n",
    "\n",
    "Here they are again, this time scaled to have the same energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.plot(impulse_resp / np.sqrt((impulse_resp ** 2).sum()))\n",
    "ax.plot(a[::-1] / np.sqrt((a ** 2).sum()))\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can estimate the non-linear function which relates the linear response to the probability of firing a spike. This is accomplished by plotting the estimated linear response versus the spike count in each 10 ms bin. It turns out that a simple scatter diagram is pretty uninformative because most of the points overlap each other..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_est = np.zeros(duration)\n",
    "for t in range(window_size, duration):\n",
    "    linear_est[t] = a @ stimulus[t - window_size:t]\n",
    "    \n",
    "linear_est = np.mean(np.split(linear_est, duration // stim_samp_time), axis=1)\n",
    "linear_est /= stim_samp_time\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.scatter(linear_est, spike_counts,  linewidth=1, fc=\"none\", ec=\"C0\")\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clean this plot up by plotting the **average** number of spikes fired in response to similar linear responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we decide on linear response bins...\n",
    "x = np.linspace(-.2, .3, 11)\n",
    "\n",
    "# ... and then calculate the average\n",
    "means = np.zeros_like(x)\n",
    "serrs = np.zeros_like(x)\n",
    "for i, x_i in enumerate(x):\n",
    "    bins = (linear_est > (x_i - .025)) & (linear_est <= (x_i + .025))\n",
    "    bin_counts = spike_counts[bins]\n",
    "    means[i] = np.mean(bin_counts)\n",
    "    serrs[i] = stats.sem(bin_counts)\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.errorbar(x, means, serrs, ls=\"\", marker=\"o\", ms=5, elinewidth=3, capsize=3)\n",
    "ax.set(xlabel=\"Linear response component\", ylabel=\"Mean spike count\")\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we decide on linear response bins...\n",
    "x = np.linspace(-.2, .3, 11)\n",
    "\n",
    "# ... and then calculate the average\n",
    "means = np.zeros_like(x)\n",
    "serrs = np.zeros_like(x)\n",
    "bins = np.digitize(linear_est, x + .025)\n",
    "for i, _ in enumerate(x):\n",
    "    bin_counts = spike_counts[bins == i]\n",
    "    means[i] = np.mean(bin_counts)\n",
    "    serrs[i] = stats.sem(bin_counts)\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.errorbar(x, means, serrs, ls=\"\", marker=\"o\", ms=5, elinewidth=3, capsize=3)\n",
    "ax.set(xlabel=\"Linear response component\", ylabel=\"Mean spike count\")\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can superimpose the non-linear function that we actually used to determine the spike firing probabilities. The plot of linear response versus mean spike count should have the same shape as this function, but remember, there was an arbitrary scale factor relating these two quantities. Below, we estimate this scale factor using least-squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_unscaled = stats.norm.cdf(alpha * x + beta)\n",
    "fit = optimize.lsq_linear(y_unscaled[:, None], means)\n",
    "grid = np.linspace(-.2, .35, 100)\n",
    "y = fit.x * stats.norm.cdf(alpha * grid + beta)\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.errorbar(x, means, serrs, ls=\"\", marker=\"o\", ms=5, elinewidth=3, capsize=3)\n",
    "ax.plot(grid, y)\n",
    "ax.set(xlabel=\"Linear response component\", ylabel=\"Mean spike count\")\n",
    "f.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cshl-tutorials (py38)",
   "language": "python",
   "name": "cshl-tutorials"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
