{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion Process Tutorial\n",
    "\n",
    "This tutorial simulates the basic diffusion (random walk) model that predicts accuracy and RTs for a 2AFC decision.\n",
    "\n",
    "- Written by G.M. Boynton, Summer 2008\n",
    "- Translated to Python by ML Waskom, Spring 2020\n",
    "\n",
    "For a great reference, see: Palmer, Huk & Shadlen (2008) Journal of Vision http://www.journalofvision.org/5/5/1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import integrate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = sum(map(ord, \"Diffusion tutorial\"))\n",
    "rng = np.random.default_rng(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a \"diffusion process\"?\n",
    "\n",
    "The basic idea is that decisions are made by accumulating information over time. Specifically, evidence is represented as a variable that increments or decrements over time based on incoming information. I can't summarize it better than Palmer, Huk and Shadlen:\n",
    "\n",
    "> \"The internal representation of the relevant stimulus is assumed to be noisy and to vary over time. Each decision is based on repeated sampling of this representation and comparing some function of these samples to a criterion. For example, suppose samples of the noisy signal are taken at discrete times and are added together to represent the evidence accumulated over time. This accumulated evidence is compared to an upper and lower bound. Upon reaching one of these bounds, the appropriate response is initiated.\n",
    ">\n",
    "> If such a random walk model is modified by reducing the time steps and evidence increments to infinitesimals, then the model in continuous time is called a diffusion model (Ratcliff, 1978; Smith, 1990). For this model, the accumulated evidence has a Gaussian distribution, which makes it a natural generalization of the Gaussian version of signal detection theory (Ratcliff, 1980).\"\n",
    "\n",
    "(Diffusion processes are also known as the Wiener process or Brownian motion)\n",
    "\n",
    "Intuitively, you can imagine how this simple model can predict error rates, and RTs for both correct and incorrect responses. In the simplest case, analytical solutions exist for accuracy and the distribution of RTs.\n",
    "\n",
    "This tutorial simulates a simple random walk model, calculating accuracy and histograms of RTs. The results of the simulation is then compared to curves generated from the analytic solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define variables for the random walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = dict(\n",
    "    a=+.1,  # Upper bound (correct)\n",
    "    b=-.1,  # Lower bound (wrong)\n",
    "    u=.1,   # Drift rate (units/sec),\n",
    "    s=.1,   # Standard deviation of drift (units/sec)\n",
    "    dt=.1,  # Step size for simulations (seconds)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick simulatoin\n",
    "\n",
    "First, let's do a quick simualtion of the random walk model without worrying about keeping track of RTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_reps = 5  # Number of staircaess per simulation\n",
    "n_steps = 30  # number of time steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the entire matrix of step sizes in a single line.\n",
    "\n",
    "In this case, step sizes are pulled from a normal distribution with mean $u \\Delta t$ and standard deviation $s \\sqrt{\\Delta t}$.  Why $\\sqrt{\\Delta t}$?  Because variance adds linearly over time, so standard deviation adds by $\\sqrt{\\Delta t}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drift = p[\"u\"] * p[\"dt\"]\n",
    "diffusion = np.sqrt(p[\"dt\"]) * rng.normal(0, p[\"s\"], (n_steps, n_reps))\n",
    "dy = drift + diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random walk is a cumulative sum of the steps (`dy`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dy.cumsum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the random walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = p[\"dt\"] * np.arange(0, n_steps)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(4, 5))\n",
    "\n",
    "# Plot the criterion and bounds\n",
    "ax.axhline(p[\"a\"], c=\".5\", ls=\"--\")\n",
    "ax.axhline(p[\"b\"], c=\".5\", ls=\"--\")\n",
    "ax.axhline(0, c=\".5\", ls=\":\")\n",
    "\n",
    "# Plot the random walks\n",
    "ax.step(t, y)\n",
    "\n",
    "ax.set(\n",
    "    xlim=(0, n_steps * p[\"dt\"]),\n",
    "    xlabel=\"Time (s)\",\n",
    ")\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second way to implement the diffusion model is to fix the up and down step sizes, and flip a biased coin to determine whether the walk goes up or down.\n",
    "\n",
    "The up and down step size is $s\\sqrt{\\Delta t}$ (the same as the standard deviation of the step size above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_step = p[\"s\"] * np.sqrt(p[\"dt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coin is biased by the drift rate.  Let's derive it.  If $p$ is the probability of going up, then the expected $\\Delta y$ of a given step is\n",
    "\n",
    "$$\n",
    "py_\\mathrm{step} - (1-p)y_\\mathrm{step} \n",
    "= (2p-1)y_\\mathrm{step}\n",
    "= s(2p - 1) \\sqrt{\\Delta t}.\n",
    "$$\n",
    "\n",
    "This should be equal to the drift rate, $u\\Delta t$.  So $s(2p - 1)\\sqrt{\\Delta t} = u\\Delta t$.  Solving for $p$ (prob) gives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = .5 * (np.sqrt(p[\"dt\"]) * p[\"u\"] / p[\"s\"] + 1)\n",
    "dy = np.where(rng.binomial(1, prob, (n_steps, n_reps)), y_step, -y_step)\n",
    "y = dy.cumsum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(4, 5))\n",
    "\n",
    "# Plot the criterion and bounds\n",
    "ax.axhline(p[\"a\"], c=\".5\", ls=\"--\")\n",
    "ax.axhline(p[\"b\"], c=\".5\", ls=\"--\")\n",
    "ax.axhline(0, c=\".5\", ls=\":\")\n",
    "\n",
    "# Plot the random walks\n",
    "ax.step(t, y)\n",
    "\n",
    "ax.set(\n",
    "    xlim=(0, n_steps * p[\"dt\"]),\n",
    "    xlabel=\"Time (s)\",\n",
    ")\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating RT distributions\n",
    "\n",
    "The walk should stop when the acculating variable hits one of the decision bounds. The time step when this happens is the RT for that trial.\n",
    "\n",
    "We'll implement this with a loop over time.  We'll only keep track of the current values of y, and only increment the walks that haven't lead to a decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_reps = 5000\n",
    "p[\"dt\"] = .001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros(n_reps)\n",
    "response = np.empty(n_reps)\n",
    "rt = np.empty(n_reps)\n",
    "alive = np.ones(n_reps, bool)\n",
    "t = 0\n",
    "\n",
    "while alive.any():\n",
    "\n",
    "    t += 1\n",
    "\n",
    "    # Take the next step\n",
    "    dy = p[\"u\"] * p[\"dt\"] + np.sqrt(p[\"dt\"]) * rng.normal(0, p[\"s\"], n_reps)\n",
    "    y += dy\n",
    "\n",
    "    # Find processes hitting the upper bound\n",
    "    a_bound = (y >= p[\"a\"]) & alive\n",
    "    response[a_bound] = +1\n",
    "    rt[a_bound] = t * p[\"dt\"]\n",
    "    alive[a_bound] = False\n",
    "\n",
    "    # Find processes hitting the lower bound\n",
    "    b_bound = (y <= p[\"b\"]) & alive\n",
    "    response[b_bound ] = -1\n",
    "    rt[b_bound] = t * p[\"dt\"]\n",
    "    alive[b_bound] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll plot the histograms of the correct and incorrect RTs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "\n",
    "bins = np.linspace(0, 5, 51)\n",
    "ax.hist(rt[response == +1], bins, label=\"Correct\")\n",
    "ax.hist(rt[response == -1], bins, label=\"Wrong\")\n",
    "\n",
    "ax.set(xlabel=\"RT (s)\")\n",
    "ax.legend()\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the simulated accuracy to the analytical solution\n",
    "\n",
    "Here is an analytical solution for the expected probability correct (derived in the Palmer reference given above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffusion_pc(a, b, u, s, **kws):\n",
    "    A = np.exp(-2 * u * a / s ** 2)\n",
    "    B = np.exp(-2 * u * b / s ** 2)\n",
    "    return (B - 1) / (B - A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = diffusion_pc(**p)\n",
    "simulated = (response == +1).mean()\n",
    "print(f\"Expected: {expected:.2%}; simulated: {simulated:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the simulated RTs to the analytical solution\n",
    "\n",
    "We can also derive the shape of the reaction time distribution on correct trials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffusion_rt_pdf(t, a, b, u, s, dt, k=20):\n",
    "\n",
    "    A = np.exp(-(t * u - 2 * a) * u / (2 * s ** 2)) / np.sqrt(2 * np.pi * 2 ** 2 * t ** 3)\n",
    "    B = 0\n",
    "\n",
    "    for k in range(-k, k + 1):\n",
    "        B += (a + 2 * k * (a + b)) * np.exp(-(a + 2 * k * (a + b)) ** 2 / (2 * t * s **2))\n",
    "\n",
    "    pc = diffusion_pc(a, b, u ,s)\n",
    "    y = A * B / pc\n",
    "    y /= integrate.trapz(y, t)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0, 30, 1001)[1:]\n",
    "pdf = diffusion_rt_pdf(t, **p)\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.plot(t, pdf, lw=3, label=\"Expected\")\n",
    "ax.hist(rt[response == 1], bins, density=True, alpha=.5, label=\"Simulated\")\n",
    "ax.set(xlim=(0, 5), xlabel=\"RT (s)\")\n",
    "ax.legend()\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercises\n",
    "\n",
    "1. Play around with the model parameters: drift rate, decision bounds - and see how the affect the accuracy and distribution of RTs. Think about how a given data set (either behavioral or physiological) can help constrain these variables. What is the signature of an increase in the decision bound? What is the signature for an increase in noise?\n",
    "\n",
    "2. Generate a psychometric function by calculating the percent correct as a function of drift rate, either through simulation or through the analytical solution.  See how the slope and threshold for this function varies with the mean and standard deviations of the drift rates. Does this make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cshl-tutorials (py38)",
   "language": "python",
   "name": "cshl-tutorials"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
